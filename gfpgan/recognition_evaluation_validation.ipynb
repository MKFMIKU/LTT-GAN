{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetArcFace(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (prelu): PReLU(num_parameters=1)\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): IRBlock(\n",
       "      (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=1)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): IRBlock(\n",
       "      (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=1)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): IRBlock(\n",
       "      (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=1)\n",
       "      (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): IRBlock(\n",
       "      (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=1)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): IRBlock(\n",
       "      (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=1)\n",
       "      (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): IRBlock(\n",
       "      (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=1)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): IRBlock(\n",
       "      (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=1)\n",
       "      (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): IRBlock(\n",
       "      (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=1)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (bn4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc5): Linear(in_features=32768, out_features=512, bias=True)\n",
       "  (bn5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from gfpgan.archs.arcface_arch import ResNetArcFace\n",
    "\n",
    "from copy import deepcopy\n",
    "def load_network(net, load_path, strict=True, param_key='params'):\n",
    "        load_net = torch.load(load_path, map_location=lambda storage, loc: storage)\n",
    "        # remove unnecessary 'module.'\n",
    "        for k, v in deepcopy(load_net).items():\n",
    "            if k.startswith('module.'):\n",
    "                load_net[k[7:]] = v\n",
    "                load_net.pop(k)\n",
    "        net.load_state_dict(load_net, strict=strict)\n",
    "\n",
    "arcface_resnet18 = ResNetArcFace(block='IRBlock', layers=[2, 2, 2, 2], use_se=False)\n",
    "load_network(arcface_resnet18, '/home/viu/Work/GFPGAN/experiments/pretrained_models/arcface_resnet18.pth')\n",
    "arcface_resnet18.cuda()\n",
    "arcface_resnet18.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tub_images = glob.glob('/data/datasets/Turbulence/CelebaAHQ100/comparisons/ab_GFPGAN_BFR/*.png')\n",
    "tub_images = glob.glob('/data/datasets/Turbulence/CelebaAHQ100/comparisons/ab_GFPGAN_g8/*.png')\n",
    "tub_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tub_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_resize_for_identity(out, size=128):\n",
    "    out_gray = (0.2989 * out[:, 0, :, :] + 0.5870 * out[:, 1, :, :] + 0.1140 * out[:, 2, :, :])\n",
    "    out_gray = out_gray.unsqueeze(1)\n",
    "    out_gray = F.interpolate(out_gray, (size, size), mode='bilinear', align_corners=False)\n",
    "    return out_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 35.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from basicsr.utils import img2tensor, tensor2img\n",
    "from torchvision.transforms.functional import normalize\n",
    "from tqdm import tqdm\n",
    "\n",
    "degs = []\n",
    "reference_img_ths = []\n",
    "tub_face_img_ths = []\n",
    "for idx in tqdm(range(len(tub_images))):\n",
    "    reference_img = cv2.imread('/data/datasets/Turbulence/CelebaAHQ100/references/' + os.path.basename(tub_images[idx]), cv2.IMREAD_UNCHANGED)\n",
    "    tub_img = cv2.imread(tub_images[idx], cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    reference_img_th = img2tensor(reference_img / 255., bgr2rgb=True, float32=True)\n",
    "    reference_img_th = reference_img_th.unsqueeze(0).cuda()\n",
    "    reference_img_th = normalize(reference_img_th, (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True)\n",
    "    reference_img_th = gray_resize_for_identity(reference_img_th)\n",
    "\n",
    "    tub_face_img_th = img2tensor(tub_img / 255., bgr2rgb=True, float32=True)\n",
    "    tub_face_img_th = tub_face_img_th.unsqueeze(0).cuda()\n",
    "    tub_face_img_th = normalize(tub_face_img_th, (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True)\n",
    "    tub_face_img_th = gray_resize_for_identity(tub_face_img_th)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tub_face_img_th = arcface_resnet18(tub_face_img_th)\n",
    "        reference_img_th = arcface_resnet18(reference_img_th)\n",
    "    reference_img_ths.append(reference_img_th)\n",
    "    tub_face_img_ths.append(tub_face_img_th)\n",
    "    deg = F.cosine_similarity(reference_img_th, tub_face_img_th).item()\n",
    "    degs.append(deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3874787329882383"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(degs) / len(degs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tub_face_img_ths = torch.cat(tub_face_img_ths)\n",
    "reference_img_ths = torch.cat(reference_img_ths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = torch.mm(reference_img_ths, tub_face_img_ths.transpose(0, 1))\n",
    "top_inds = torch.argsort(-similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4, 91, 68,  7,  8,  9, 10,  7, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 28, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        61, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
       "        72, 73, 74, 75, 61, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_inds[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top1 = 0.94\n"
     ]
    }
   ],
   "source": [
    "# top1\n",
    "correct_num = 0\n",
    "for i in range(tub_face_img_ths.size(0)):\n",
    "    j = top_inds[i, 0]\n",
    "    # if j//3 == i//3:\n",
    "    if j == i:\n",
    "        correct_num += 1\n",
    "print(\"top1 = {}\".format(correct_num / tub_face_img_ths.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top3 = 0.7415730337078652\n"
     ]
    }
   ],
   "source": [
    "# top3\n",
    "correct_num = 0\n",
    "for i in range(tub_face_img_ths.size(0)):\n",
    "    # j = top_inds[i, 0:9]\n",
    "    # if i//3 in j//3:\n",
    "    j = top_inds[i, 0:3]\n",
    "    if i in j:\n",
    "        correct_num += 1\n",
    "print(\"top3 = {}\".format(correct_num / tub_face_img_ths.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top5 = 0.7865168539325843\n"
     ]
    }
   ],
   "source": [
    "# top5\n",
    "correct_num = 0\n",
    "for i in range(tub_face_img_ths.size(0)):\n",
    "    j = top_inds[i, 0:5]\n",
    "    if i in j:\n",
    "    # j = top_inds[i, 0:15]\n",
    "    # if i//3 in j//3:\n",
    "        correct_num += 1\n",
    "print(\"top5 = {}\".format(correct_num / tub_face_img_ths.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73955261ad6c5c670f7deaf4fb6b560a15bffc3940fd0e108b78aadbd2945a88"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
